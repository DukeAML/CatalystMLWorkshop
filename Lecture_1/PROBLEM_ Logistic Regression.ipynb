{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fr36Ovfr2VfGhZF1zUoUgD7k6Uceu9T3","timestamp":1679446920305},{"file_id":"1-Slk6y5-E3eUnmM4vjtoRrGMoIKvD0hU","timestamp":1621226380691}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0MRC0e0KhQ0S"},"source":["# Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"LWd1UlMnhT2s"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"YvGPUQaHhXfL","executionInfo":{"status":"ok","timestamp":1679514890647,"user_tz":240,"elapsed":326,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1VMqkGvhc3-"},"source":["## Importing the dataset"]},{"cell_type":"code","metadata":{"id":"M52QDmyzhh9s","executionInfo":{"status":"ok","timestamp":1679514890648,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Reading in a CSV file containing data \n","dataset = pd.read_csv('Social_Network_Ads.csv')"],"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Outputting information about the dataset\n","dataset.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2fkcrh42VdS","executionInfo":{"status":"ok","timestamp":1679514890648,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}},"outputId":"a0027bee-f713-46cf-ce6c-4e542cc33afb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 400 entries, 0 to 399\n","Data columns (total 3 columns):\n"," #   Column           Non-Null Count  Dtype\n","---  ------           --------------  -----\n"," 0   Age              400 non-null    int64\n"," 1   EstimatedSalary  400 non-null    int64\n"," 2   Purchased        400 non-null    int64\n","dtypes: int64(3)\n","memory usage: 9.5 KB\n"]}]},{"cell_type":"markdown","source":["The code is calling the `info()` method, which provides information about the data frame, including the number of rows and columns, the column names, the number of non-null values in each column, and the data types of the columns. The output of this method is useful for understanding the structure and content of the dataset, and can be used to inform data cleaning and analysis tasks."],"metadata":{"id":"JzKkjlukqqzG"}},{"cell_type":"code","source":["# Generating descriptive statistics about the dataset\n","dataset.describe()"],"metadata":{"id":"rXYu6m0NrTP2","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1679514890648,"user_tz":240,"elapsed":7,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}},"outputId":"e015bd42-a3f1-4d1c-891d-3bea692a021e"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Age  EstimatedSalary   Purchased\n","count  400.000000       400.000000  400.000000\n","mean    37.655000     69742.500000    0.357500\n","std     10.482877     34096.960282    0.479864\n","min     18.000000     15000.000000    0.000000\n","25%     29.750000     43000.000000    0.000000\n","50%     37.000000     70000.000000    0.000000\n","75%     46.000000     88000.000000    1.000000\n","max     60.000000    150000.000000    1.000000"],"text/html":["\n","  <div id=\"df-a5464298-6dfe-4666-9a7c-2919db3136ee\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>EstimatedSalary</th>\n","      <th>Purchased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>400.000000</td>\n","      <td>400.000000</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>37.655000</td>\n","      <td>69742.500000</td>\n","      <td>0.357500</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>10.482877</td>\n","      <td>34096.960282</td>\n","      <td>0.479864</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>18.000000</td>\n","      <td>15000.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>29.750000</td>\n","      <td>43000.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>37.000000</td>\n","      <td>70000.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>46.000000</td>\n","      <td>88000.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>60.000000</td>\n","      <td>150000.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5464298-6dfe-4666-9a7c-2919db3136ee')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a5464298-6dfe-4666-9a7c-2919db3136ee button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a5464298-6dfe-4666-9a7c-2919db3136ee');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["The code is calling the `describe()` method, which generates descriptive statistics about the data frame, including the count, mean, standard deviation, minimum and maximum values, and quartiles for each numeric column in the data frame. The output of this method is useful for getting a sense of the distribution of the data and identifying potential issues such as missing values, outliers, or anomalies. It can also help inform data cleaning and analysis tasks."],"metadata":{"id":"xLS_DMErrTr5"}},{"cell_type":"code","source":["# Displaying the first few rows of the dataset\n","dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"2x1mA3bp2WQo","executionInfo":{"status":"ok","timestamp":1679514890648,"user_tz":240,"elapsed":6,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}},"outputId":"419055f8-b668-4a63-a5c3-eae1ab15a147"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Age  EstimatedSalary  Purchased\n","0   19            19000          0\n","1   35            20000          0\n","2   26            43000          0\n","3   27            57000          0\n","4   19            76000          0"],"text/html":["\n","  <div id=\"df-775ee58b-fda3-4344-91c1-09f539d1303a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>EstimatedSalary</th>\n","      <th>Purchased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>19</td>\n","      <td>19000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>35</td>\n","      <td>20000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26</td>\n","      <td>43000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>57000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19</td>\n","      <td>76000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-775ee58b-fda3-4344-91c1-09f539d1303a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-775ee58b-fda3-4344-91c1-09f539d1303a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-775ee58b-fda3-4344-91c1-09f539d1303a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["The code is calling the `head()`, which displays the first few rows of the data frame, by default the first 5 rows. This can be useful for getting a quick overview of the dataset, including the column names and the values in the first few rows. The output of this method is often used to check that the data has been imported correctly and to get a sense of the data's structure and content."],"metadata":{"id":"RvfMTyGIqrZP"}},{"cell_type":"markdown","source":["We are trying to predict whether a customer purchased a product, which is the last column. This is a discrete variable of either 0 or 1"],"metadata":{"id":"deXuMOct2nuO"}},{"cell_type":"markdown","source":["We thus split the data into the variables we want to use to predict the variable Purchased, and the variable Purchased.\n"],"metadata":{"id":"x6u_riwT3Cus"}},{"cell_type":"markdown","source":["`iloc` is a pandas method for selecting subsets of data based on integer-based indexing.\n","\n","`[:, :-1]` selects all rows (:) and all columns except the last one (:-1) as the input features.\n","\n","`[:, -1]` selects all rows (:) and only the last column (-1) as the output labels.\n","\n","`.values` returns the data as a NumPy array."],"metadata":{"id":"ggZJXipa3Uua"}},{"cell_type":"code","source":["# Select all rows and all columns except the last one as the features (input data) and assign it to X\n","X = dataset.iloc[:, :-1].values\n","\n","# Select all rows and only the last column as the labels (output data) and assign it to y\n","y = dataset.iloc[:, -1].values"],"metadata":{"id":"boY75pnX2VA9","executionInfo":{"status":"ok","timestamp":1679514890648,"user_tz":240,"elapsed":6,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvxIPVyMhmKp"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"GGPuwhB03f-W","executionInfo":{"status":"ok","timestamp":1679514892228,"user_tz":240,"elapsed":1585,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["`train_test_split` is a function from the sklearn.model_selection module that splits input features and output labels into random train and test subsets."],"metadata":{"id":"rvCSirdg3rcA"}},{"cell_type":"markdown","source":["The first two arguments (`X` and `y`) are the input features and output labels to be split."],"metadata":{"id":"0LFyhK6a4Y9x"}},{"cell_type":"markdown","source":["`test_size = 0.25` specifies that 25% of the input features and output labels will be used for testing, and the remaining 75% will be used for training."],"metadata":{"id":"46MiS0ic4bO5"}},{"cell_type":"markdown","source":["`random_state = 0` sets the random seed for reproducibility of the train/test split."],"metadata":{"id":"MZ8fElbp4cmm"}},{"cell_type":"markdown","source":["The function returns four output tuples, in the order `(X_train, X_test, y_train, y_test)` which correspond to the training and testing subsets of the input features and output labels, respectively."],"metadata":{"id":"1qCtc42l4eR2"}},{"cell_type":"code","metadata":{"id":"AVzJWAXIhxoC","executionInfo":{"status":"ok","timestamp":1679514892229,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Split the input features (X) and output labels (y) into training and testing sets using a 75/25 ratio and a fixed random state\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# X_train.shape"],"metadata":{"id":"KVXW4fwQ3dGh","executionInfo":{"status":"ok","timestamp":1679514892229,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# X_test.shape"],"metadata":{"id":"e6OcWJab3h25","executionInfo":{"status":"ok","timestamp":1679514892229,"user_tz":240,"elapsed":8,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# y_train.shape"],"metadata":{"id":"YMqZdqo03iNz","executionInfo":{"status":"ok","timestamp":1679514892229,"user_tz":240,"elapsed":8,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# y_test.shape"],"metadata":{"id":"-EZ9V9Cv3oS_","executionInfo":{"status":"ok","timestamp":1679514892230,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kW3c7UYih0hT"},"source":["## Feature Scaling"]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"-CV5MRPE4L6J","executionInfo":{"status":"ok","timestamp":1679514892230,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["`StandardScaler` is a class from the sklearn.preprocessing module that scales input features to have a mean of 0 and variance of 1."],"metadata":{"id":"AV0T4eWL4TNh"}},{"cell_type":"markdown","source":["`sc` is an instance of the `StandardScaler` class that will be used to scale the input features."],"metadata":{"id":"vzMRzP216ENl"}},{"cell_type":"markdown","source":["`fit_transform` is a method of the `StandardScaler` class that both fits the scaler to the training input features (i.e., calculates the mean and variance to be used for scaling) and applies the same transformation to the training input features."],"metadata":{"id":"bslNS7Dx6Hcs"}},{"cell_type":"markdown","source":["`transform` is a method of the StandardScaler class that applies the same transformation (scaling) that was calculated from the training input features to the testing input features."],"metadata":{"id":"Lv89N4Mg6Hfd"}},{"cell_type":"code","metadata":{"id":"9fQlDPKCh8sc","executionInfo":{"status":"ok","timestamp":1679514892230,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Create a StandardScaler object to standardize (normalize) the input features\n","\n","#Scale whole matrix of features to prevent information leakage\n","\n","# Fit the scaler to the training input features and apply the same transformation to the testing input features\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Overall, this code is scaling (normalizing) the input features to prevent information leakage between the training and testing sets. By standardizing the input features, it helps ensure that the features have a similar scale and distribution, which can help improve the accuracy and stability of the machine learning model."],"metadata":{"id":"TQSZaX936Pvm"}},{"cell_type":"markdown","metadata":{"id":"bb6jCOCQiAmP"},"source":["## Training the Logistic Regression model on the Training set"]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"oZrq--q460Fu","executionInfo":{"status":"ok","timestamp":1679514892230,"user_tz":240,"elapsed":8,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["`LogisticRegression` is a class from the `sklearn.linear_model` module that implements logistic regression for binary classification tasks.\n"],"metadata":{"id":"Apgl5tcu66kA"}},{"cell_type":"markdown","source":["`random_state = 0` sets the random seed for reproducibility of the logistic regression model."],"metadata":{"id":"i79Pf9CL7Elp"}},{"cell_type":"markdown","source":["`classifier` is an instance of the LogisticRegression class that will be used to fit and predict with the logistic regression model."],"metadata":{"id":"Y689XAur7ErW"}},{"cell_type":"markdown","source":["`fit` is a method of the `LogisticRegression` class that trains (fits) the logistic regression model using the training input features (`X_train`) and output labels (`y_train`)."],"metadata":{"id":"WXGL5ki_7ExJ"}},{"cell_type":"code","metadata":{"id":"e0pFVAmciHQs","executionInfo":{"status":"ok","timestamp":1679514892230,"user_tz":240,"elapsed":8,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Create a LogisticRegression object with a fixed random state\n","\n","# Train (fit) the model using the training input features (X_train) and output labels (y_train)\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Overall, this code is creating and training a logistic regression model using the training input features and output labels. The `random_state` parameter ensures reproducibility of the model fitting, while `fit` actually trains the model on the training data. Once the model has been trained, it can be used to make predictions on new data.\n","\n","\n","\n"],"metadata":{"id":"Irg3UrO369Cl"}},{"cell_type":"markdown","metadata":{"id":"yyxW5b395mR2"},"source":["## Predicting a new result"]},{"cell_type":"markdown","source":["`predict` is a method of the `LogisticRegression` class that makes predictions on new data points using the trained logistic regression model.\n"],"metadata":{"id":"jr64UQoF7jIY"}},{"cell_type":"markdown","source":["`sc.transform` is used to scale (normalize) the input features of the new data point in the same way as the training data."],"metadata":{"id":"Nnn6R-zc7kza"}},{"cell_type":"markdown","source":["`[[30,87000]]` is a nested list containing the input features of the new data point. In this case, the new data point has an age of 30 and a salary of 87000.\n"],"metadata":{"id":"uPTSuXsj7k2C"}},{"cell_type":"markdown","source":["The output of `predict` is a binary value (0 or 1) indicating the predicted class label of the new data point. In this case, the predicted class label is not provided in the code snippet."],"metadata":{"id":"pA1us5pL7k5T"}},{"cell_type":"code","metadata":{"id":"f8YOXsQy58rP","executionInfo":{"status":"ok","timestamp":1679514892231,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Use the trained logistic regression classifier to make a prediction on a new data point\n","# Here, the age is 30 and the salary is 87000\n","# The input data is first transformed using the same scaling as the training data\n","# The output prediction is a binary value (0 or 1) indicating the predicted class label\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Overall, this code is using the trained logistic regression classifier to make a prediction on a new data point with an age of 30 and a salary of 87000. The input data is first transformed using the same scaling as the training data, and the output prediction is a binary value indicating the predicted class label."],"metadata":{"id":"hWPIKn3s7h0R"}},{"cell_type":"markdown","metadata":{"id":"vKYVQH-l5NpE"},"source":["## Predicting the Test set results"]},{"cell_type":"code","metadata":{"id":"p6VMTb2O4hwM","executionInfo":{"status":"ok","timestamp":1679514892231,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Use the test output to make a prediction, and name this prediction y_pred"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["The function below is a utility function that can be used to create a DataFrame that compares predicted and actual values for a binary classification problem.\n","\n","You do not need to understand this as it is mostly for show, but if you are curious:\n","\n","The function uses the `np.concatenate` function to concatenate the `y_pred` and `y_test` arrays along the second axis to create a two-dimensional array named data.\n","\n","The `reshape` method is used to ensure that the `y_pred` and `y_test` arrays are column vectors."],"metadata":{"id":"xR4d9hDP9rDo"}},{"cell_type":"code","source":["def predictions_vs_actual(y_pred, y_test):\n","    \"\"\"Returns a DataFrame that compares predicted and actual values.\n","\n","    Args:\n","        y_pred (array-like): An array of predicted values for a binary classification problem.\n","        y_test (array-like): An array of actual values for the same binary classification problem.\n","\n","    Returns:\n","        pandas.DataFrame: A DataFrame with two columns named 'Predicted' and 'Actual'.\n","\n","    \"\"\"\n","    # Concatenate the predicted and actual values along the second axis to create a two-dimensional array\n","    data = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1)\n","    # Create a DataFrame from the two-dimensional array with columns 'Predicted' and 'Actual'\n","    df = pd.DataFrame(data=data, columns=['Predicted', 'Actual'])\n","    # Return the DataFrame\n","    return df"],"metadata":{"id":"ncCWKW0o87j0","executionInfo":{"status":"ok","timestamp":1679514892231,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Use the above method to compare the predictions to the actual results"],"metadata":{"id":"HMUk6FhY86Pp","executionInfo":{"status":"ok","timestamp":1679514892231,"user_tz":240,"elapsed":8,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4Hwj34ziWQW"},"source":["## Making the Confusion Matrix"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score"],"metadata":{"id":"JpLnu5U-78Yb","executionInfo":{"status":"ok","timestamp":1679514892231,"user_tz":240,"elapsed":8,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["`confusion_matrix` is a function from the `sklearn.metrics` module that computes the confusion matrix for a classifier given the true labels and predicted labels.\n"],"metadata":{"id":"wzDzbsJD7_1_"}},{"cell_type":"markdown","source":["`y_test` contains the true class labels for the testing data."],"metadata":{"id":"iJBP-v2c7_5P"}},{"cell_type":"markdown","source":["`y_pred` contains the predicted class labels for the testing data."],"metadata":{"id":"VULhyOCN8Ut0"}},{"cell_type":"markdown","source":["The confusion matrix is a table with four entries: true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN)."],"metadata":{"id":"qa6Y8pGb8UxV"}},{"cell_type":"markdown","source":["`TP` represents the number of true positive predictions, `TN` represents the number of true negative predictions, `FP` represents the number of false positive predictions, and `FN` represents the number of false negative predictions."],"metadata":{"id":"Ib_RUsNF8U6n"}},{"cell_type":"markdown","source":["The diagonal of the confusion matrix shows the correct predictions (TP and TN), while the off-diagonal elements show the incorrect predictions (FP and FN)."],"metadata":{"id":"TQNH-qQp8dgA"}},{"cell_type":"code","metadata":{"id":"D6bpZwUiiXic","executionInfo":{"status":"ok","timestamp":1679514892232,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"source":["# Compute the confusion matrix and print it out\n","# A confusion matrix is a table used to evaluate the performance of a classifier\n","# The confusion matrix shows the number of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions\n","# TP: actual positive and predicted positive\n","# TN: actual negative and predicted negative\n","# FP: actual negative but predicted positive\n","# FN: actual positive but predicted negative\n","# The diagonal of the matrix shows the correct predictions (TP and TN)\n","# The off-diagonal elements show the incorrect predictions (FP and FN)\n","# Here, y_test contains the true labels of the testing data, and y_pred contains the predicted labels\n"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["`accuracy_score` is a function from the `sklearn.metrics` module that computes the accuracy of a classifier given the true labels and predicted labels."],"metadata":{"id":"ieIsNX2v8gB-"}},{"cell_type":"markdown","source":["The accuracy is the proportion of correct predictions (TP and TN) out of all predictions."],"metadata":{"id":"6GKkp_AU8jaZ"}},{"cell_type":"code","source":["# Compute the accuracy of the classifier and print it out\n","# The accuracy is the proportion of correct predictions (TP and TN) out of all predictions\n","# Here, y_test contains the true labels of the testing data, and y_pred contains the predicted labels\n"],"metadata":{"id":"nkJDKleI8MWc","executionInfo":{"status":"ok","timestamp":1679514892232,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["Overall, this code is evaluating the performance of the logistic regression classifier using the testing data. The confusion matrix shows the number of true positives, false positives, true negatives, and false negatives, and the accuracy score shows the proportion of correct predictions out of all predictions. These metrics are useful for evaluating the performance of a classifier and for comparing the performance of different classifiers."],"metadata":{"id":"qcZz-20Y8AT-"}},{"cell_type":"markdown","metadata":{"id":"6OMC_P0diaoD"},"source":["## Visualising the Training set results"]},{"cell_type":"markdown","source":["This utility function is used to visualize the decision boundary of a logistic regression model along with the training or test data. The function takes in the feature array `X` and target array `y`, as well as a string `train_test` indicating whether the visualization is for the training or test set."],"metadata":{"id":"uE_GMTZzAA-p"}},{"cell_type":"markdown","source":["You do not need to understand this as it is mostly for show, but if you are curious:\n","\n","The function first transforms `X` to the original scale and assigns the transformed `X` and `y` to new variables. Then, it creates a meshgrid of points using `numpy.meshgrid` to plot the decision boundary. The `start`, `stop`, and `step` arguments of `numpy.arange` are used to define the ranges and spacing of the points on the meshgrid.\n","\n","The decision boundary is plotted using `plt.contourf`, which predicts the target variable for all points in the meshgrid using the logistic regression model `classifier` and the transformed feature array `sc.transform`. The `alpha` argument controls the transparency of the decision boundary, and the `cmap` argument controls the color scheme.\n","\n","The limits of the plot are set to the minimum and maximum values of X1 and X2 using `plt.xlim` and `plt.ylim`. The training or test data is plotted using plt.scatter, with points color-coded by class label. The title and axis labels of the plot are set using `plt.title`, `plt.xlabel`, and `plt.ylabel`. The legend is shown using plt.legend, and the plot is displayed using `plt.show`.\n","\n"],"metadata":{"id":"eKcgSOYnAMPA"}},{"cell_type":"code","source":["from matplotlib.colors import ListedColormap"],"metadata":{"id":"IwPqZ6WL-AtN","executionInfo":{"status":"ok","timestamp":1679514892232,"user_tz":240,"elapsed":9,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def visualize_data(X, y, train_test = 'Train'):\n","  \"\"\"\n","  Function to visualize the data and decision boundary of the Logistic Regression model.\n","\n","  Parameters:\n","  -----------\n","  X : numpy array\n","      The feature array.\n","  y : numpy array\n","      The target array.\n","  train_test : str, optional (default='Train')\n","      The string to indicate if the visualization is for 'Train' or 'Test' data.\n","\n","  Returns:\n","  --------\n","  None\n","  \"\"\"\n","\n","  # Transform X to original scale and assign X and y to new variables\n","  X_set, y_set = sc.inverse_transform(X), y\n","\n","  # Create a meshgrid of points to plot decision boundary\n","  X1, X2 = np.meshgrid(\n","      np.arange(\n","          start = X_set[:, 0].min() - 10, \n","          stop = X_set[:, 0].max() + 10, \n","          step = 0.25\n","      ),\n","      np.arange(\n","          start = X_set[:, 1].min() - 1000, \n","          stop = X_set[:, 1].max() + 1000, \n","          step = 0.25\n","      )\n","  )\n","\n","  # Plot the decision boundary by predicting the target variable \n","  # for all points in the meshgrid\n","  plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n","              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n","  \n","  # Set the limits of the plot to the minimum and maximum values \n","  # of X1 and X2\n","  plt.xlim(X1.min(), X1.max())\n","  plt.ylim(X2.min(), X2.max())\n","\n","  # Plot the data points, color-coded by class label\n","  for i, j in enumerate(np.unique(y_set)):\n","      plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n","  \n","  # Set the title and labels of the plot, and show the legend\n","  plt.title(f'Logistic Regression ({train_test}ing set)')\n","  plt.xlabel('Age')\n","  plt.ylabel('Estimated Salary')\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"BvJAg4aR9-l0","executionInfo":{"status":"ok","timestamp":1679514892587,"user_tz":240,"elapsed":5,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Use the visualizaiton method above the visualize the training results of logistic regression\n"],"metadata":{"id":"Mab9Vf8U-N4V","executionInfo":{"status":"ok","timestamp":1679514892588,"user_tz":240,"elapsed":5,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["## Visualising the Test set results"],"metadata":{"id":"cYKJau9E-jo6"}},{"cell_type":"code","source":["# Make a graph similar to above with the test set"],"metadata":{"id":"W1WIbCaa-Q1Z","executionInfo":{"status":"ok","timestamp":1679514892588,"user_tz":240,"elapsed":4,"user":{"displayName":"Havish Malladi","userId":"11496466906719043812"}}},"execution_count":27,"outputs":[]}]}